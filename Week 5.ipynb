{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "import folium\n",
    "import json\n",
    "import requests\n",
    "import codecs\n",
    "\n",
    "try:\n",
    "  import geocoder\n",
    "except:\n",
    "  !pip install geocoder\n",
    "  import geocoder\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.geocoders import Nominatim\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.cluster import KMeans\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://en.wikipedia.org/wiki/Category:Arrondissements_of_Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = codecs.open('Category:Arrondissements_of_Paris', encoding='utf-8').read()\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_district_name(district_name):\n",
    "  if '►  ' in district_name:\n",
    "    district_name = district_name.replace('►  ', '')\n",
    "#  if 'District' not in district_name:\n",
    "#    district_name += ' District'\n",
    "  return district_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "districts = [li.text.split('\\n') for li in soup.find_all('ul')[1:2]]\n",
    "districts = list(flatten(districts))\n",
    "districts = [clean_district_name(dist) for dist in districts]\n",
    "\n",
    "print('There are {} districts in Paris.'.format(len(districts)))\n",
    "districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district = [d[0:19] for d in districts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent='ibm-capstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_lat = []\n",
    "districts_lng = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dist in district:\n",
    "    location = geolocator.geocode(dist, timeout=10000)\n",
    "    districts_lat.append(location.latitude)\n",
    "    districts_lng.append(location.longitude)\n",
    "\n",
    "print('{} latitudes and {} longitudes were found.'.format(len(districts_lat), len(districts_lng)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Paris, FR'\n",
    "Paris_geo = geolocator.geocode(city, timeout=10000)\n",
    "Paris_lat = Paris_geo.latitude\n",
    "Paris_lng = Paris_geo.longitude\n",
    "\n",
    "print('The latitude and longitude of {} are {}, {}.'.format(city, Paris_lat, Paris_lng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    'District': district,\n",
    "    'Latitude': districts_lat,\n",
    "    'Longitude': districts_lng\n",
    "})\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Paris_arrondissement_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get venues of each district within a radius of 5km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foursquare cresentials and version\n",
    "CLIENT_ID = 'SBZ3SIXQKQG5BNV3EK2N3FFVVDVOVA0MAM3BBLMWAADRZCNN'\n",
    "CLIENT_SECRET = 'PH53JIKBY32YJZ1PJVDY5APEXP2ZVX5R5KH0F4RULNELOTA0'\n",
    "VERSION = '20200101'\n",
    "SECTION = 'arts'\n",
    "LIMIT = 50\n",
    "RADIUS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(district, latitudes, longitudes):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for district, lat, lng in zip(district, latitudes, longitudes):\n",
    "        print(district)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}&section={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            RADIUS, \n",
    "            LIMIT,\n",
    "            SECTION)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()['response']['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            district,\n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['District',\n",
    "                            'District Latitude', \n",
    "                            'District Longitude', \n",
    "                            'Venue', \n",
    "                            'Venue Latitude', \n",
    "                            'Venue Longitude', \n",
    "                            'Venue Category']\n",
    "              \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_venues = getNearbyVenues(district=df['District'],\n",
    "                              latitudes=df['Latitude'],\n",
    "                              longitudes=df['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_venues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_venues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_venues.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_venues['Venue Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_dict = Paris_venues.groupby('District').count()[['Venue']]\n",
    "venue_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_dict.sort_values(by='Venue', ascending=False).plot.bar()\n",
    "plt.xlabel('District')\n",
    "plt.ylabel('Number of venues')\n",
    "plt.legend('')\n",
    "plt.title('Number of venues in Paris')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_category = Paris_venues.groupby('Venue Category').count()[['Venue']]\n",
    "venue_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_category.sort_values(by='Venue', ascending=False).plot.bar()\n",
    "plt.xlabel('Venue Category')\n",
    "plt.ylabel('Number of venues')\n",
    "plt.legend('')\n",
    "plt.title('Top most common venue categories in Paris')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_category.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_venues['Venue Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "Paris_onehot = pd.get_dummies(Paris_venues[['Venue Category']], prefix='', prefix_sep='')\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "Paris_onehot['District'] = Paris_venues[['District']]\n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [Paris_onehot.columns[-1]] + list(Paris_onehot.columns[:-1])\n",
    "Paris_onehot = Paris_onehot[fixed_columns]\n",
    "\n",
    "Paris_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_grouped = Paris_onehot.groupby('District').mean().reset_index()\n",
    "Paris_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_grouped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top 6 most common venues of each district\n",
    "num_top_venues = 6\n",
    "\n",
    "for dist in Paris_grouped['District']:\n",
    "    print('----'+dist+'----')\n",
    "    # get a dataframe of venues according to neigborhood and transpose it \n",
    "    temp = Paris_grouped[Paris_grouped['District'] == dist].T.reset_index()\n",
    "    \n",
    "    # update meaningful column names\n",
    "    temp.columns = ['Venue Category', 'Frequency']\n",
    "    \n",
    "    # remove the first row of the dataframe (the previous 'District' column)\n",
    "    temp = temp.iloc[1:]\n",
    "    \n",
    "    # convert 'freq' column to type float\n",
    "    temp['Frequency'] = temp['Frequency'].astype(float)\n",
    "    \n",
    "    # round the 'freq' column to 2 digit\n",
    "    temp = temp.round({'Frequency': 2})\n",
    "    \n",
    "    # sort the dataframe desceningly\n",
    "    temp.sort_values(by='Frequency', ascending=False, inplace=True)\n",
    "    \n",
    "    # reset and drop index\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    \n",
    "    print(temp[:6])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['District']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['District'] = Paris_grouped['District']\n",
    "\n",
    "for ind in np.arange(Paris_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(Paris_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 5\n",
    "\n",
    "Paris_grouped_clustering = Paris_grouped.drop('District', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(Paris_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "try:  \n",
    "  neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "except:\n",
    "  neighborhoods_venues_sorted = neighborhoods_venues_sorted\n",
    "Paris_merged = df\n",
    "\n",
    "# merge Paris_grouped with Paris_data to add latitude/longitude for each neighborhood\n",
    "Paris_merged = Paris_merged.join(neighborhoods_venues_sorted.set_index('District'), on='District')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Paris_merged.dropna(inplace=True)\n",
    "Paris_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[Paris_lat, Paris_lng], zoom_start=10)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(Paris_merged['Latitude'], Paris_merged['Longitude'], Paris_merged['District'], Paris_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[int(cluster -1)],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[int(cluster-1)],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 0\n",
    "Paris_merged.loc[Paris_merged['Cluster Labels'] == 0, Paris_merged.columns[[0] + list(range(4, Paris_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 1\n",
    "Paris_merged.loc[Paris_merged['Cluster Labels'] == 1, Paris_merged.columns[[0] + list(range(4, Paris_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 2\n",
    "Paris_merged.loc[Paris_merged['Cluster Labels'] == 2, Paris_merged.columns[[0] + list(range(4, Paris_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 3\n",
    "Paris_merged.loc[Paris_merged['Cluster Labels'] == 3, Paris_merged.columns[[0] + list(range(4, Paris_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 4\n",
    "Paris_merged.loc[Paris_merged['Cluster Labels'] == 4, Paris_merged.columns[[0] + list(range(4, Paris_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster 5\n",
    "Paris_merged.loc[Paris_merged['Cluster Labels'] == 5, Paris_merged.columns[[0] + list(range(4, Paris_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
